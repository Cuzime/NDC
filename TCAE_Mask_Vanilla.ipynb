{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tunable Compression Autoencoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.image as mpimg\n",
    "import random\n",
    "import math\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow import keras \n",
    "from keras import layers\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.layers.convolutional.conv2d_transpose import Conv2DTranspose\n",
    "from keras.layers.reshaping.up_sampling2d import UpSampling2D\n",
    "\n",
    "import wandb\n",
    "from wandb.keras import WandbMetricsLogger, WandbModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/andrewgoh/Desktop/NDC/wandb/run-20230309_185116-1ywb0vt4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cuzime/prelim%20/runs/1ywb0vt4' target=\"_blank\">misty-cosmos-23</a></strong> to <a href='https://wandb.ai/cuzime/prelim%20' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cuzime/prelim%20' target=\"_blank\">https://wandb.ai/cuzime/prelim%20</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cuzime/prelim%20/runs/1ywb0vt4' target=\"_blank\">https://wandb.ai/cuzime/prelim%20/runs/1ywb0vt4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# WANDB CONFIG\n",
    "\n",
    "# start run, tracking hyperparameters\n",
    "wandb.init(\n",
    "    #set project\n",
    "    project = \"prelim\",\n",
    "\n",
    "    config = {\n",
    "        \"epochs\": 3,\n",
    "        \"batch_size\": 64,\n",
    "        \"latent_dim\": 8,\n",
    "        \"num_encoding_layers\": 3,\n",
    "        \"num_decoding_layers\": 3,\n",
    "        \"enc_num_filters_1\": 128,\n",
    "        \"enc_num_filters_2\": 64,\n",
    "        \"enc_num_filters_3\": 32,\n",
    "        \"dec_num_filters_1\": 32,\n",
    "        \"dec_num_filters_2\": 64,\n",
    "        \"dec_num_filters_3\": 128,\n",
    "        \"metrics\": \"accuracy\"\n",
    "    }\n",
    "\n",
    ")\n",
    "\n",
    "config = wandb.config\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 28, 28, 1)\n",
      "(60000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# Prepare the dataset. We use both the training & test MNIST digits.\n",
    "\n",
    "(x_train, _), (x_test, _) = keras.datasets.mnist.load_data()\n",
    "\n",
    "all_digits = np.concatenate([x_train, x_test])\n",
    "all_digits = all_digits.astype(\"float32\") / 255.0\n",
    "all_digits = np.reshape(all_digits, (-1, 28, 28, 1))\n",
    "\n",
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_train = np.reshape(x_train, (-1, 28, 28, 1))\n",
    "\n",
    "x_test = x_test.astype(\"float32\") / 255.0\n",
    "x_test = np.reshape(x_test, (-1, 28, 28, 1))\n",
    "\n",
    "print(np.shape(all_digits))\n",
    "print(np.shape(x_train))\n",
    "print(np.shape(x_test))\n",
    "\n",
    "batch_size = config.batch_size\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(all_digits)\n",
    "dataset = dataset.shuffle(buffer_size = 1024).batch(batch_size)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(x_train)\n",
    "train_dataset = train_dataset.shuffle(buffer_size = 1024).batch(batch_size)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(x_test)\n",
    "test_dataset = test_dataset.shuffle(buffer_size = 1024).batch(batch_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range = 13,\n",
    "    zoom_range = 0.1, \n",
    "    shear_range = 10, \n",
    "    width_shift_range = 0.03,\n",
    "    height_shift_range = 0.03,\n",
    ")\n",
    "\n",
    "datagen.fit(x_train)\n",
    "\n",
    "train_generator = datagen.flow(x_train, batch_size = config.batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fceef188cd0>"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = random.randint(0, 100)\n",
    "i = random.randint(0, 31)\n",
    "random_image = train_generator.__getitem__(idx)[i].reshape(28,28)\n",
    "\n",
    "\n",
    "plt.imshow(random_image, cmap = 'gray')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TCAE (MASKS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_244\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_444 (Conv2D)         (None, 28, 28, 128)       1280      \n",
      "                                                                 \n",
      " batch_normalization_241 (Ba  (None, 28, 28, 128)      512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_926 (Activation)  (None, 28, 28, 128)      0         \n",
      "                                                                 \n",
      " max_pooling2d_425 (MaxPooli  (None, 14, 14, 128)      0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_445 (Conv2D)         (None, 14, 14, 64)        73792     \n",
      "                                                                 \n",
      " activation_927 (Activation)  (None, 14, 14, 64)       0         \n",
      "                                                                 \n",
      " max_pooling2d_426 (MaxPooli  (None, 7, 7, 64)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_446 (Conv2D)         (None, 7, 7, 64)          36928     \n",
      "                                                                 \n",
      " activation_928 (Activation)  (None, 7, 7, 64)         0         \n",
      "                                                                 \n",
      " max_pooling2d_427 (MaxPooli  (None, 4, 4, 64)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_447 (Conv2D)         (None, 4, 4, 32)          18464     \n",
      "                                                                 \n",
      " activation_929 (Activation)  (None, 4, 4, 32)         0         \n",
      "                                                                 \n",
      " flatten_125 (Flatten)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_244 (Dense)           (None, 8)                 4104      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 135,080\n",
      "Trainable params: 134,824\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_245\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_245 (Dense)           (None, 1568)              14112     \n",
      "                                                                 \n",
      " reshape_119 (Reshape)       (None, 7, 7, 32)          0         \n",
      "                                                                 \n",
      " conv2d_transpose_482 (Conv2  (None, 7, 7, 32)         9248      \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " activation_930 (Activation)  (None, 7, 7, 32)         0         \n",
      "                                                                 \n",
      " up_sampling2d_265 (UpSampli  (None, 14, 14, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_transpose_483 (Conv2  (None, 14, 14, 32)       9248      \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " activation_931 (Activation)  (None, 14, 14, 32)       0         \n",
      "                                                                 \n",
      " up_sampling2d_266 (UpSampli  (None, 28, 28, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_transpose_484 (Conv2  (None, 28, 28, 64)       18496     \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " activation_932 (Activation)  (None, 28, 28, 64)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_485 (Conv2  (None, 28, 28, 128)      73856     \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " batch_normalization_242 (Ba  (None, 28, 28, 128)      512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_933 (Activation)  (None, 28, 28, 128)      0         \n",
      "                                                                 \n",
      " conv2d_transpose_486 (Conv2  (None, 28, 28, 1)        513       \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " activation_934 (Activation)  (None, 28, 28, 1)        0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 125,985\n",
      "Trainable params: 125,729\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (28,28,1)\n",
    "\n",
    "latent_dim = config.latent_dim\n",
    "\n",
    "# encoder \n",
    "\n",
    "def make_encoder(num_layers, num_filters_1, num_filters_2, num_filters_3):\n",
    "\n",
    "    init_filters = num_filters_1\n",
    "\n",
    "    encoder = keras.Sequential()\n",
    "    encoder.add(keras.Input(shape = input_shape))\n",
    "    encoder.add(layers.Conv2D(init_filters, (3,3), padding = 'same'))\n",
    "    encoder.add(layers.BatchNormalization())\n",
    "    encoder.add(layers.Activation('relu'))\n",
    "    encoder.add(layers.MaxPooling2D((2,2),padding = 'same'))\n",
    "\n",
    "    for i in range(2):\n",
    "        encoder.add(layers.Conv2D(num_filters_2, (3,3), activation = 'relu', padding = 'same'))\n",
    "        encoder.add(layers.Activation('relu'))\n",
    "        encoder.add(layers.MaxPooling2D((2,2),padding = 'same'))\n",
    "\n",
    "    for i in range(num_layers-2):\n",
    "        encoder.add(layers.Conv2D(num_filters_3, (3,3), activation = 'relu', padding = 'same'))\n",
    "        encoder.add(layers.Activation('relu'))\n",
    "\n",
    "    encoder.add(layers.Flatten())\n",
    "    encoder.add(layers.Dense(latent_dim, activation = 'relu'))  \n",
    "\n",
    "    return encoder\n",
    "\n",
    "# decoder\n",
    "\n",
    "def make_decoder(num_layers, num_filters_1, num_filters_2, num_filters_3):\n",
    "\n",
    "    decoder = keras.Sequential()\n",
    "    decoder.add(keras.Input(shape = (latent_dim,)))\n",
    "    decoder.add(layers.Dense(7*7*32, activation = 'relu'))\n",
    "    decoder.add(layers.Reshape(target_shape = (7,7,32)))\n",
    "\n",
    "    for i in range(2):\n",
    "        decoder.add(Conv2DTranspose(num_filters_1, (3,3), padding = 'same'))\n",
    "        decoder.add(layers.Activation('relu'))\n",
    "        decoder.add(UpSampling2D((2,2)))\n",
    "    \n",
    "    for i in range(num_layers-2):\n",
    "        decoder.add(Conv2DTranspose(num_filters_2, (3,3), padding = 'same'))\n",
    "        decoder.add(layers.Activation('relu'))\n",
    "        \n",
    "    decoder.add(Conv2DTranspose(num_filters_3, (3,3), padding = 'same'))\n",
    "    decoder.add(layers.BatchNormalization())\n",
    "    decoder.add(layers.Activation('relu'))\n",
    "\n",
    "    decoder.add(Conv2DTranspose(1, (2,2), padding = 'same'))\n",
    "    decoder.add(layers.Activation('sigmoid'))\n",
    "\n",
    "    return decoder\n",
    "\n",
    "# define number of layers\n",
    "num_encoding_layers = config.num_encoding_layers\n",
    "num_decoding_layers = config.num_decoding_layers\n",
    "\n",
    "# make encoder\n",
    "encoder = make_encoder(num_layers = num_encoding_layers, \n",
    "                       num_filters_1 = config.enc_num_filters_1, \n",
    "                       num_filters_2 = config.enc_num_filters_2, \n",
    "                       num_filters_3 = config.enc_num_filters_3)\n",
    "encoder.summary()\n",
    "\n",
    "'''# get preflattened shape \n",
    "pre_flatten_shape = K.int_shape(encoder.layers[-3].output)[1:]\n",
    "print(pre_flatten_shape)\n",
    "\n",
    "dense_out = 1\n",
    "for elem in pre_flatten_shape:\n",
    "    dense_out *= elem'''\n",
    "\n",
    "# make decoder \n",
    "decoder = make_decoder(num_layers = num_decoding_layers, \n",
    "                       num_filters_1 = config.dec_num_filters_1, \n",
    "                       num_filters_2 = config.dec_num_filters_2, \n",
    "                       num_filters_3 = config.dec_num_filters_3)\n",
    "\n",
    "decoder.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TCAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.avg_loss_tracker = keras.metrics.Mean(name = 'avg_loss')\n",
    "        self.avg_accuracy_tracker = keras.metrics.Mean(name = 'avg_accuracy')\n",
    "\n",
    "    def compile(self, optimizer, loss_fn, accuracy_fn):\n",
    "        super().compile()\n",
    "        self.optimizer = optimizer \n",
    "        self.loss_fn = loss_fn\n",
    "        self.accuracy_fn = accuracy_fn\n",
    "\n",
    "    def train_step(self, data):\n",
    "\n",
    "        avg_loss = 0\n",
    "        avg_accuracy = 0\n",
    "\n",
    "        for i in range(int(np.log2(latent_dim)+1)):\n",
    "\n",
    "            with tf.GradientTape() as tape:\n",
    "                # create mask\n",
    "                ones_length = int(2**(np.log2(latent_dim)-i))\n",
    "                zeros_length = int(latent_dim - ones_length)\n",
    "                ones = tf.ones((ones_length)) \n",
    "                zeros = tf.zeros((zeros_length))\n",
    "                mask = tf.concat([ones, zeros], axis = 0) \n",
    "                mask = tf.reshape(mask, (1,latent_dim))\n",
    "     \n",
    "                codes = self.encoder(data)\n",
    "                masked_codes = tf.multiply(codes, mask)\n",
    "                #print(codes.shape)\n",
    "                #print(mask.shape)\n",
    "                #print(masked_codes.shape)\n",
    "                #masked_codes = tf.reshape(masked_codes, (tf.shape(codes)[0], latent_dim))\n",
    "                \n",
    "                reconstruction = self.decoder(masked_codes)\n",
    "\n",
    "                loss = self.loss_fn(data, reconstruction)\n",
    "                accuracy = self.accuracy_fn(data, reconstruction)\n",
    "            \n",
    "            avg_loss += loss\n",
    "            avg_accuracy += accuracy\n",
    "            # get gradients\n",
    "            grads = tape.gradient(loss, self.trainable_weights)\n",
    "            # apply gradients\n",
    "            self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "\n",
    "        avg_loss = avg_loss / int(np.log2(latent_dim)+1)\n",
    "        avg_accuracy = avg_accuracy / int(np.log2(latent_dim+1))\n",
    "            \n",
    "        self.avg_loss_tracker.update_state(avg_loss)\n",
    "        self.avg_accuracy_tracker.update_state(avg_accuracy)\n",
    "\n",
    "        return {\n",
    "            'avg_loss': self.avg_loss_tracker.result(),\n",
    "            'avg_accuracy': self.avg_accuracy_tracker.result()\n",
    "        }\n",
    "\n",
    "    def custom_predict(self, data, n):\n",
    "\n",
    "        # create mask\n",
    "        ones_length = int(2**(n))\n",
    "        zeros_length = int(latent_dim - ones_length)\n",
    "        ones = tf.ones((ones_length)) \n",
    "        zeros = tf.zeros((zeros_length))\n",
    "        mask = tf.concat([ones, zeros], axis = 0) \n",
    "        mask = tf.reshape(mask, (1,latent_dim))\n",
    "\n",
    "        codes = self.encoder(data)\n",
    "        masked_codes = tf.multiply(codes, mask)\n",
    "        #masked_codes = tf.reshape(masked_codes, (1, latent_dim))\n",
    "        \n",
    "        reconstruction = self.decoder(masked_codes)\n",
    "\n",
    "        return reconstruction\n",
    "\n",
    "    def test_step(self, data):\n",
    "        \n",
    "        avg_loss = 0\n",
    "        avg_accuracy = 0\n",
    "\n",
    "        for i in range(int(np.log2(latent_dim)+1)):\n",
    "            # create mask\n",
    "            ones_length = int(2**(np.log2(latent_dim)-i))\n",
    "            zeros_length = int(latent_dim - ones_length)\n",
    "            ones = tf.ones((ones_length)) \n",
    "            zeros = tf.zeros((zeros_length))\n",
    "            mask = tf.concat([ones, zeros], axis = 0) \n",
    "            mask = tf.reshape(mask, (1,latent_dim))\n",
    "\n",
    "            # mask codes\n",
    "            codes = self.encoder(data)\n",
    "            masked_codes = tf.multiply(codes, mask)        \n",
    "            reconstruction = self.decoder(masked_codes)\n",
    "\n",
    "            loss = self.loss_fn(data, reconstruction)\n",
    "            accuracy = self.accuracy_fn(data, reconstruction)\n",
    "            \n",
    "            avg_loss += loss\n",
    "            avg_accuracy += accuracy\n",
    "        \n",
    "        avg_loss = avg_loss / int(np.log2(latent_dim)+1)\n",
    "        avg_accuracy = avg_accuracy / int(np.log2(latent_dim+1))\n",
    "            \n",
    "        self.avg_loss_tracker.update_state(avg_loss)\n",
    "        self.avg_accuracy_tracker.update_state(avg_accuracy)\n",
    "\n",
    "\n",
    "        return {\n",
    "            'avg_loss': self.avg_loss_tracker.result(),\n",
    "            'avg_accuracy': self.avg_accuracy_tracker.result()\n",
    "        }\n",
    "    \n",
    "    def call(self, data):\n",
    "        codes = self.encoder(data)\n",
    "        reconstruction = self.decoder(codes)\n",
    "\n",
    "        return reconstruction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# test masking \n",
    "\n",
    "i = 2\n",
    "\n",
    "ones_length = int(2**(i))\n",
    "zeros_length = int(latent_dim - ones_length)\n",
    "ones = tf.ones((ones_length)) \n",
    "zeros = tf.zeros((zeros_length))\n",
    "mask = tf.concat([ones, zeros], axis = 0)\n",
    "mask = tf.reshape(mask, (1, latent_dim,))\n",
    "\n",
    "a = mask.numpy()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize tcae\n",
    "\n",
    "tcae = TCAE(encoder = encoder, decoder = decoder)\n",
    "tcae.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001), \n",
    "             loss_fn = tf.keras.losses.binary_crossentropy, \n",
    "             accuracy_fn = tf.keras.metrics.BinaryAccuracy(name=\"binary_accuracy\", dtype=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "938/938 [==============================] - ETA: 0s - avg_loss: 0.2268 - avg_accuracy: 0.9798"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./models)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 1574s 2s/step - avg_loss: 0.2268 - avg_accuracy: 0.9798 - val_avg_loss: 0.1915 - val_avg_accuracy: 1.0737\n",
      "Epoch 2/3\n",
      "938/938 [==============================] - ETA: 0s - avg_loss: 0.2083 - avg_accuracy: 0.9813"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./models)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 1547s 2s/step - avg_loss: 0.2083 - avg_accuracy: 0.9813 - val_avg_loss: 0.1840 - val_avg_accuracy: 1.0722\n",
      "Epoch 3/3\n",
      "938/938 [==============================] - ETA: 0s - avg_loss: 0.2040 - avg_accuracy: 0.9822"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./models)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 1534s 2s/step - avg_loss: 0.2040 - avg_accuracy: 0.9822 - val_avg_loss: 0.1797 - val_avg_accuracy: 1.0754\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch/avg_accuracy</td><td>▁▅▆▆▆▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇█████████████</td></tr><tr><td>batch/avg_loss</td><td>█▆▄▄▄▃▃▃▃▃▃▃▃▁▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>batch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/avg_accuracy</td><td>▁▅█</td></tr><tr><td>epoch/avg_loss</td><td>█▂▁</td></tr><tr><td>epoch/epoch</td><td>▁▅█</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁</td></tr><tr><td>epoch/val_avg_accuracy</td><td>▄▁█</td></tr><tr><td>epoch/val_avg_loss</td><td>█▄▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch/avg_accuracy</td><td>0.98223</td></tr><tr><td>batch/avg_loss</td><td>0.20397</td></tr><tr><td>batch/batch_step</td><td>2815</td></tr><tr><td>batch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/avg_accuracy</td><td>0.98223</td></tr><tr><td>epoch/avg_loss</td><td>0.20396</td></tr><tr><td>epoch/epoch</td><td>2</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/val_avg_accuracy</td><td>1.07542</td></tr><tr><td>epoch/val_avg_loss</td><td>0.17974</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">misty-cosmos-23</strong> at: <a href='https://wandb.ai/cuzime/prelim%20/runs/1ywb0vt4' target=\"_blank\">https://wandb.ai/cuzime/prelim%20/runs/1ywb0vt4</a><br/>Synced 6 W&B file(s), 0 media file(s), 15 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230309_185116-1ywb0vt4/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = config.epochs\n",
    "\n",
    "tcae.fit(train_generator, epochs = epochs, validation_data = test_dataset,\n",
    "                   callbacks = [\n",
    "                    WandbMetricsLogger(log_freq=5),\n",
    "                    WandbModelCheckpoint(\"models\", save_best_only = True, monitor = 'val_avg_loss')\n",
    "                   ])\n",
    "wandb.finish()\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"save weights\"\"\"\n",
    "#tcae.save_weights('/Users/andrewgoh/Desktop/NDC/weights/tcae_weights', overwrite=True, save_format=None, options=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"load weights\"\"\"\n",
    "\"\"\"tcae = TCAE(encoder = encoder, decoder = decoder)\n",
    "tcae.load_weights('/Users/andrewgoh/Desktop/NDC/weights/tcae_weights', by_name=False, skip_mismatch=False, options=None)\n",
    "\n",
    "# set optimizer and compile \n",
    "tcae.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001), loss_fn = tf.keras.losses.BinaryCrossentropy())\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x360 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = random.randint(0, np.shape(all_digits)[0]-1)\n",
    "img = all_digits[index,:,:,0]\n",
    "\n",
    "plt.figure(figsize = (3,3))\n",
    "plt.imshow(img)\n",
    "\n",
    "img = img.reshape(1, 28, 28, 1)\n",
    "\n",
    "plt.figure(figsize = (16,5))\n",
    "for i in range(int(np.log2(latent_dim))+1):\n",
    "    ax = plt.subplot(2, 8, i + 1)\n",
    "    reconstruction = tcae.custom_predict([img], np.log2(latent_dim)-i)\n",
    "    reconstruction = reconstruction.numpy().reshape(28,28)\n",
    "    plt.title('latent dim:{}'.format(int(2**(np.log2(latent_dim)-i))))\n",
    "    plt.imshow(reconstruction)\n",
    "    plt.axis('off')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
