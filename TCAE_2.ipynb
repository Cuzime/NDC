{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tunable Compression Autoencoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.image as mpimg\n",
    "import random\n",
    "import math\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow import keras \n",
    "from keras import layers\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.layers.convolutional.conv2d_transpose import Conv2DTranspose\n",
    "from keras.layers.reshaping.up_sampling2d import UpSampling2D\n",
    "\n",
    "import wandb\n",
    "from wandb.keras import WandbMetricsLogger, WandbModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/andrewgoh/Desktop/NDC/wandb/run-20230309_185116-1ywb0vt4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cuzime/prelim%20/runs/1ywb0vt4' target=\"_blank\">misty-cosmos-23</a></strong> to <a href='https://wandb.ai/cuzime/prelim%20' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cuzime/prelim%20' target=\"_blank\">https://wandb.ai/cuzime/prelim%20</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cuzime/prelim%20/runs/1ywb0vt4' target=\"_blank\">https://wandb.ai/cuzime/prelim%20/runs/1ywb0vt4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# WANDB CONFIG\n",
    "\n",
    "# start run, tracking hyperparameters\n",
    "wandb.init(\n",
    "    #set project\n",
    "    project = \"prelim\",\n",
    "\n",
    "    config = {\n",
    "        \"epochs\": 3,\n",
    "        \"batch_size\": 64,\n",
    "        \"latent_dim\": 8,\n",
    "        \"num_encoding_layers\": 3,\n",
    "        \"num_decoding_layers\": 3,\n",
    "        \"enc_num_filters_1\": 128,\n",
    "        \"enc_num_filters_2\": 64,\n",
    "        \"enc_num_filters_3\": 32,\n",
    "        \"dec_num_filters_1\": 32,\n",
    "        \"dec_num_filters_2\": 64,\n",
    "        \"dec_num_filters_3\": 128,\n",
    "        \"metrics\": \"accuracy\"\n",
    "    }\n",
    "\n",
    ")\n",
    "\n",
    "config = wandb.config\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 28, 28, 1)\n",
      "(60000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# Prepare the dataset. We use both the training & test MNIST digits.\n",
    "\n",
    "(x_train, _), (x_test, _) = keras.datasets.mnist.load_data()\n",
    "\n",
    "all_digits = np.concatenate([x_train, x_test])\n",
    "all_digits = all_digits.astype(\"float32\") / 255.0\n",
    "all_digits = np.reshape(all_digits, (-1, 28, 28, 1))\n",
    "\n",
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_train = np.reshape(x_train, (-1, 28, 28, 1))\n",
    "\n",
    "x_test = x_test.astype(\"float32\") / 255.0\n",
    "x_test = np.reshape(x_test, (-1, 28, 28, 1))\n",
    "\n",
    "print(np.shape(all_digits))\n",
    "print(np.shape(x_train))\n",
    "print(np.shape(x_test))\n",
    "\n",
    "batch_size = config.batch_size\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(all_digits)\n",
    "dataset = dataset.shuffle(buffer_size = 1024).batch(batch_size)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(x_train)\n",
    "train_dataset = train_dataset.shuffle(buffer_size = 1024).batch(batch_size)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(x_test)\n",
    "test_dataset = test_dataset.shuffle(buffer_size = 1024).batch(batch_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range = 13,\n",
    "    zoom_range = 0.1, \n",
    "    shear_range = 10, \n",
    "    width_shift_range = 0.03,\n",
    "    height_shift_range = 0.03,\n",
    ")\n",
    "\n",
    "datagen.fit(x_train)\n",
    "\n",
    "train_generator = datagen.flow(x_train, batch_size = config.batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fceef188cd0>"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = random.randint(0, 100)\n",
    "i = random.randint(0, 31)\n",
    "random_image = train_generator.__getitem__(idx)[i].reshape(28,28)\n",
    "\n",
    "\n",
    "plt.imshow(random_image, cmap = 'gray')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TCAE (MASKS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_244\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_444 (Conv2D)         (None, 28, 28, 128)       1280      \n",
      "                                                                 \n",
      " batch_normalization_241 (Ba  (None, 28, 28, 128)      512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_926 (Activation)  (None, 28, 28, 128)      0         \n",
      "                                                                 \n",
      " max_pooling2d_425 (MaxPooli  (None, 14, 14, 128)      0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_445 (Conv2D)         (None, 14, 14, 64)        73792     \n",
      "                                                                 \n",
      " activation_927 (Activation)  (None, 14, 14, 64)       0         \n",
      "                                                                 \n",
      " max_pooling2d_426 (MaxPooli  (None, 7, 7, 64)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_446 (Conv2D)         (None, 7, 7, 64)          36928     \n",
      "                                                                 \n",
      " activation_928 (Activation)  (None, 7, 7, 64)         0         \n",
      "                                                                 \n",
      " max_pooling2d_427 (MaxPooli  (None, 4, 4, 64)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_447 (Conv2D)         (None, 4, 4, 32)          18464     \n",
      "                                                                 \n",
      " activation_929 (Activation)  (None, 4, 4, 32)         0         \n",
      "                                                                 \n",
      " flatten_125 (Flatten)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_244 (Dense)           (None, 8)                 4104      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 135,080\n",
      "Trainable params: 134,824\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_245\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_245 (Dense)           (None, 1568)              14112     \n",
      "                                                                 \n",
      " reshape_119 (Reshape)       (None, 7, 7, 32)          0         \n",
      "                                                                 \n",
      " conv2d_transpose_482 (Conv2  (None, 7, 7, 32)         9248      \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " activation_930 (Activation)  (None, 7, 7, 32)         0         \n",
      "                                                                 \n",
      " up_sampling2d_265 (UpSampli  (None, 14, 14, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_transpose_483 (Conv2  (None, 14, 14, 32)       9248      \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " activation_931 (Activation)  (None, 14, 14, 32)       0         \n",
      "                                                                 \n",
      " up_sampling2d_266 (UpSampli  (None, 28, 28, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_transpose_484 (Conv2  (None, 28, 28, 64)       18496     \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " activation_932 (Activation)  (None, 28, 28, 64)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_485 (Conv2  (None, 28, 28, 128)      73856     \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " batch_normalization_242 (Ba  (None, 28, 28, 128)      512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_933 (Activation)  (None, 28, 28, 128)      0         \n",
      "                                                                 \n",
      " conv2d_transpose_486 (Conv2  (None, 28, 28, 1)        513       \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " activation_934 (Activation)  (None, 28, 28, 1)        0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 125,985\n",
      "Trainable params: 125,729\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (28,28,1)\n",
    "\n",
    "latent_dim = config.latent_dim\n",
    "\n",
    "# encoder \n",
    "\n",
    "def make_encoder(num_layers, num_filters_1, num_filters_2, num_filters_3):\n",
    "\n",
    "    init_filters = num_filters_1\n",
    "\n",
    "    encoder = keras.Sequential()\n",
    "    encoder.add(keras.Input(shape = input_shape))\n",
    "    encoder.add(layers.Conv2D(init_filters, (3,3), padding = 'same'))\n",
    "    encoder.add(layers.BatchNormalization())\n",
    "    encoder.add(layers.Activation('relu'))\n",
    "    encoder.add(layers.MaxPooling2D((2,2),padding = 'same'))\n",
    "\n",
    "    for i in range(2):\n",
    "        encoder.add(layers.Conv2D(num_filters_2, (3,3), activation = 'relu', padding = 'same'))\n",
    "        encoder.add(layers.Activation('relu'))\n",
    "        encoder.add(layers.MaxPooling2D((2,2),padding = 'same'))\n",
    "\n",
    "    for i in range(num_layers-2):\n",
    "        encoder.add(layers.Conv2D(num_filters_3, (3,3), activation = 'relu', padding = 'same'))\n",
    "        encoder.add(layers.Activation('relu'))\n",
    "\n",
    "    encoder.add(layers.Flatten())\n",
    "    encoder.add(layers.Dense(latent_dim, activation = 'relu'))  \n",
    "\n",
    "    return encoder\n",
    "\n",
    "# decoder\n",
    "\n",
    "def make_decoder(num_layers, num_filters_1, num_filters_2, num_filters_3):\n",
    "\n",
    "    decoder = keras.Sequential()\n",
    "    decoder.add(keras.Input(shape = (latent_dim,)))\n",
    "    decoder.add(layers.Dense(7*7*32, activation = 'relu'))\n",
    "    decoder.add(layers.Reshape(target_shape = (7,7,32)))\n",
    "\n",
    "    for i in range(2):\n",
    "        decoder.add(Conv2DTranspose(num_filters_1, (3,3), padding = 'same'))\n",
    "        decoder.add(layers.Activation('relu'))\n",
    "        decoder.add(UpSampling2D((2,2)))\n",
    "    \n",
    "    for i in range(num_layers-2):\n",
    "        decoder.add(Conv2DTranspose(num_filters_2, (3,3), padding = 'same'))\n",
    "        decoder.add(layers.Activation('relu'))\n",
    "        \n",
    "    decoder.add(Conv2DTranspose(num_filters_3, (3,3), padding = 'same'))\n",
    "    decoder.add(layers.BatchNormalization())\n",
    "    decoder.add(layers.Activation('relu'))\n",
    "\n",
    "    decoder.add(Conv2DTranspose(1, (2,2), padding = 'same'))\n",
    "    decoder.add(layers.Activation('sigmoid'))\n",
    "\n",
    "    return decoder\n",
    "\n",
    "# define number of layers\n",
    "num_encoding_layers = config.num_encoding_layers\n",
    "num_decoding_layers = config.num_decoding_layers\n",
    "\n",
    "# make encoder\n",
    "encoder = make_encoder(num_layers = num_encoding_layers, \n",
    "                       num_filters_1 = config.enc_num_filters_1, \n",
    "                       num_filters_2 = config.enc_num_filters_2, \n",
    "                       num_filters_3 = config.enc_num_filters_3)\n",
    "encoder.summary()\n",
    "\n",
    "'''# get preflattened shape \n",
    "pre_flatten_shape = K.int_shape(encoder.layers[-3].output)[1:]\n",
    "print(pre_flatten_shape)\n",
    "\n",
    "dense_out = 1\n",
    "for elem in pre_flatten_shape:\n",
    "    dense_out *= elem'''\n",
    "\n",
    "# make decoder \n",
    "decoder = make_decoder(num_layers = num_decoding_layers, \n",
    "                       num_filters_1 = config.dec_num_filters_1, \n",
    "                       num_filters_2 = config.dec_num_filters_2, \n",
    "                       num_filters_3 = config.dec_num_filters_3)\n",
    "\n",
    "decoder.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TCAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.avg_loss_tracker = keras.metrics.Mean(name = 'avg_loss')\n",
    "        self.avg_accuracy_tracker = keras.metrics.Mean(name = 'avg_accuracy')\n",
    "\n",
    "    def compile(self, optimizer, loss_fn, accuracy_fn):\n",
    "        super().compile()\n",
    "        self.optimizer = optimizer \n",
    "        self.loss_fn = loss_fn\n",
    "        self.accuracy_fn = accuracy_fn\n",
    "\n",
    "    def train_step(self, data):\n",
    "\n",
    "        avg_loss = 0\n",
    "        avg_accuracy = 0\n",
    "\n",
    "        for i in range(int(np.log2(latent_dim)+1)):\n",
    "\n",
    "            with tf.GradientTape() as tape:\n",
    "                # create mask\n",
    "                ones_length = int(2**(np.log2(latent_dim)-i))\n",
    "                zeros_length = int(latent_dim - ones_length)\n",
    "                ones = tf.ones((ones_length)) \n",
    "                zeros = tf.zeros((zeros_length))\n",
    "                mask = tf.concat([ones, zeros], axis = 0) \n",
    "                mask = tf.reshape(mask, (1,latent_dim))\n",
    "     \n",
    "                codes = self.encoder(data)\n",
    "                masked_codes = tf.multiply(codes, mask)\n",
    "                #print(codes.shape)\n",
    "                #print(mask.shape)\n",
    "                #print(masked_codes.shape)\n",
    "                #masked_codes = tf.reshape(masked_codes, (tf.shape(codes)[0], latent_dim))\n",
    "                \n",
    "                reconstruction = self.decoder(masked_codes)\n",
    "\n",
    "                loss = self.loss_fn(data, reconstruction)\n",
    "                accuracy = self.accuracy_fn(data, reconstruction)\n",
    "            \n",
    "            avg_loss += loss\n",
    "            avg_accuracy += accuracy\n",
    "            # get gradients\n",
    "            grads = tape.gradient(loss, self.trainable_weights)\n",
    "            # apply gradients\n",
    "            self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "\n",
    "        avg_loss = avg_loss / int(np.log2(latent_dim)+1)\n",
    "        avg_accuracy = avg_accuracy / int(np.log2(latent_dim+1))\n",
    "            \n",
    "        self.avg_loss_tracker.update_state(avg_loss)\n",
    "        self.avg_accuracy_tracker.update_state(avg_accuracy)\n",
    "\n",
    "        return {\n",
    "            'avg_loss': self.avg_loss_tracker.result(),\n",
    "            'avg_accuracy': self.avg_accuracy_tracker.result()\n",
    "        }\n",
    "\n",
    "    def custom_predict(self, data, n):\n",
    "\n",
    "        # create mask\n",
    "        ones_length = int(2**(n))\n",
    "        zeros_length = int(latent_dim - ones_length)\n",
    "        ones = tf.ones((ones_length)) \n",
    "        zeros = tf.zeros((zeros_length))\n",
    "        mask = tf.concat([ones, zeros], axis = 0) \n",
    "        mask = tf.reshape(mask, (1,latent_dim))\n",
    "\n",
    "        codes = self.encoder(data)\n",
    "        masked_codes = tf.multiply(codes, mask)\n",
    "        #masked_codes = tf.reshape(masked_codes, (1, latent_dim))\n",
    "        \n",
    "        reconstruction = self.decoder(masked_codes)\n",
    "\n",
    "        return reconstruction\n",
    "\n",
    "    def test_step(self, data):\n",
    "        \n",
    "        avg_loss = 0\n",
    "        avg_accuracy = 0\n",
    "\n",
    "        for i in range(int(np.log2(latent_dim)+1)):\n",
    "            # create mask\n",
    "            ones_length = int(2**(np.log2(latent_dim)-i))\n",
    "            zeros_length = int(latent_dim - ones_length)\n",
    "            ones = tf.ones((ones_length)) \n",
    "            zeros = tf.zeros((zeros_length))\n",
    "            mask = tf.concat([ones, zeros], axis = 0) \n",
    "            mask = tf.reshape(mask, (1,latent_dim))\n",
    "\n",
    "            # mask codes\n",
    "            codes = self.encoder(data)\n",
    "            masked_codes = tf.multiply(codes, mask)        \n",
    "            reconstruction = self.decoder(masked_codes)\n",
    "\n",
    "            loss = self.loss_fn(data, reconstruction)\n",
    "            accuracy = self.accuracy_fn(data, reconstruction)\n",
    "            \n",
    "            avg_loss += loss\n",
    "            avg_accuracy += accuracy\n",
    "        \n",
    "        avg_loss = avg_loss / int(np.log2(latent_dim)+1)\n",
    "        avg_accuracy = avg_accuracy / int(np.log2(latent_dim+1))\n",
    "            \n",
    "        self.avg_loss_tracker.update_state(avg_loss)\n",
    "        self.avg_accuracy_tracker.update_state(avg_accuracy)\n",
    "\n",
    "\n",
    "        return {\n",
    "            'avg_loss': self.avg_loss_tracker.result(),\n",
    "            'avg_accuracy': self.avg_accuracy_tracker.result()\n",
    "        }\n",
    "    \n",
    "    def call(self, data):\n",
    "        codes = self.encoder(data)\n",
    "        reconstruction = self.decoder(codes)\n",
    "\n",
    "        return reconstruction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# test masking \n",
    "\n",
    "i = 2\n",
    "\n",
    "ones_length = int(2**(i))\n",
    "zeros_length = int(latent_dim - ones_length)\n",
    "ones = tf.ones((ones_length)) \n",
    "zeros = tf.zeros((zeros_length))\n",
    "mask = tf.concat([ones, zeros], axis = 0)\n",
    "mask = tf.reshape(mask, (1, latent_dim,))\n",
    "\n",
    "a = mask.numpy()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize tcae\n",
    "\n",
    "tcae = TCAE(encoder = encoder, decoder = decoder)\n",
    "tcae.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001), \n",
    "             loss_fn = tf.keras.losses.binary_crossentropy, \n",
    "             accuracy_fn = tf.keras.metrics.BinaryAccuracy(name=\"binary_accuracy\", dtype=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "938/938 [==============================] - ETA: 0s - avg_loss: 0.2268 - avg_accuracy: 0.9798"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./models)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 1574s 2s/step - avg_loss: 0.2268 - avg_accuracy: 0.9798 - val_avg_loss: 0.1915 - val_avg_accuracy: 1.0737\n",
      "Epoch 2/3\n",
      "938/938 [==============================] - ETA: 0s - avg_loss: 0.2083 - avg_accuracy: 0.9813"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./models)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 1547s 2s/step - avg_loss: 0.2083 - avg_accuracy: 0.9813 - val_avg_loss: 0.1840 - val_avg_accuracy: 1.0722\n",
      "Epoch 3/3\n",
      "938/938 [==============================] - ETA: 0s - avg_loss: 0.2040 - avg_accuracy: 0.9822"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./models)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 1534s 2s/step - avg_loss: 0.2040 - avg_accuracy: 0.9822 - val_avg_loss: 0.1797 - val_avg_accuracy: 1.0754\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch/avg_accuracy</td><td>▁▅▆▆▆▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇█████████████</td></tr><tr><td>batch/avg_loss</td><td>█▆▄▄▄▃▃▃▃▃▃▃▃▁▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>batch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/avg_accuracy</td><td>▁▅█</td></tr><tr><td>epoch/avg_loss</td><td>█▂▁</td></tr><tr><td>epoch/epoch</td><td>▁▅█</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁</td></tr><tr><td>epoch/val_avg_accuracy</td><td>▄▁█</td></tr><tr><td>epoch/val_avg_loss</td><td>█▄▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch/avg_accuracy</td><td>0.98223</td></tr><tr><td>batch/avg_loss</td><td>0.20397</td></tr><tr><td>batch/batch_step</td><td>2815</td></tr><tr><td>batch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/avg_accuracy</td><td>0.98223</td></tr><tr><td>epoch/avg_loss</td><td>0.20396</td></tr><tr><td>epoch/epoch</td><td>2</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/val_avg_accuracy</td><td>1.07542</td></tr><tr><td>epoch/val_avg_loss</td><td>0.17974</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">misty-cosmos-23</strong> at: <a href='https://wandb.ai/cuzime/prelim%20/runs/1ywb0vt4' target=\"_blank\">https://wandb.ai/cuzime/prelim%20/runs/1ywb0vt4</a><br/>Synced 6 W&B file(s), 0 media file(s), 15 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230309_185116-1ywb0vt4/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = config.epochs\n",
    "\n",
    "tcae.fit(train_generator, epochs = epochs, validation_data = test_dataset,\n",
    "                   callbacks = [\n",
    "                    WandbMetricsLogger(log_freq=5),\n",
    "                    WandbModelCheckpoint(\"models\", save_best_only = True, monitor = 'val_avg_loss')\n",
    "                   ])\n",
    "wandb.finish()\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"save weights\"\"\"\n",
    "#tcae.save_weights('/Users/andrewgoh/Desktop/NDC/weights/tcae_weights', overwrite=True, save_format=None, options=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"load weights\"\"\"\n",
    "\"\"\"tcae = TCAE(encoder = encoder, decoder = decoder)\n",
    "tcae.load_weights('/Users/andrewgoh/Desktop/NDC/weights/tcae_weights', by_name=False, skip_mismatch=False, options=None)\n",
    "\n",
    "# set optimizer and compile \n",
    "tcae.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001), loss_fn = tf.keras.losses.BinaryCrossentropy())\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x360 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = random.randint(0, np.shape(all_digits)[0]-1)\n",
    "img = all_digits[index,:,:,0]\n",
    "\n",
    "plt.figure(figsize = (3,3))\n",
    "plt.imshow(img)\n",
    "\n",
    "img = img.reshape(1, 28, 28, 1)\n",
    "\n",
    "plt.figure(figsize = (16,5))\n",
    "for i in range(int(np.log2(latent_dim))+1):\n",
    "    ax = plt.subplot(2, 8, i + 1)\n",
    "    reconstruction = tcae.custom_predict([img], np.log2(latent_dim)-i)\n",
    "    reconstruction = reconstruction.numpy().reshape(28,28)\n",
    "    plt.title('latent dim:{}'.format(int(2**(np.log2(latent_dim)-i))))\n",
    "    plt.imshow(reconstruction)\n",
    "    plt.axis('off')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
