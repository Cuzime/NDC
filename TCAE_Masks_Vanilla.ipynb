{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tunable Compression Autoencoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.image as mpimg\n",
    "import random\n",
    "import math\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow import keras \n",
    "from keras import layers\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.layers.convolutional.conv2d_transpose import Conv2DTranspose\n",
    "from keras.layers.reshaping.up_sampling2d import UpSampling2D\n",
    "\n",
    "import wandb\n",
    "from wandb.keras import WandbMetricsLogger, WandbModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33magoh\u001b[0m (\u001b[33mcuzime\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/andrewgoh/Desktop/NDC/wandb/run-20230309_214150-01gyrtm7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cuzime/prelim%20/runs/01gyrtm7' target=\"_blank\">stoic-violet-24</a></strong> to <a href='https://wandb.ai/cuzime/prelim%20' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cuzime/prelim%20' target=\"_blank\">https://wandb.ai/cuzime/prelim%20</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cuzime/prelim%20/runs/01gyrtm7' target=\"_blank\">https://wandb.ai/cuzime/prelim%20/runs/01gyrtm7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# WANDB CONFIG\n",
    "\n",
    "# start run, tracking hyperparameters\n",
    "wandb.init(\n",
    "    #set project\n",
    "    project = \"prelim\",\n",
    "\n",
    "    config = {\n",
    "        \"epochs\": 3,\n",
    "        \"batch_size\": 64,\n",
    "        \"latent_dim\": 16,\n",
    "        \"num_encoding_layers\": 3,\n",
    "        \"num_decoding_layers\": 3,\n",
    "        \"enc_num_filters_1\": 128,\n",
    "        \"enc_num_filters_2\": 64,\n",
    "        \"enc_num_filters_3\": 32,\n",
    "        \"dec_num_filters_1\": 32,\n",
    "        \"dec_num_filters_2\": 64,\n",
    "        \"dec_num_filters_3\": 128,\n",
    "        \"metrics\": \"accuracy\"\n",
    "    }\n",
    "\n",
    ")\n",
    "\n",
    "config = wandb.config\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 28, 28, 1)\n",
      "(60000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# Prepare the dataset. We use both the training & test MNIST digits.\n",
    "\n",
    "(x_train, _), (x_test, _) = keras.datasets.mnist.load_data()\n",
    "\n",
    "all_digits = np.concatenate([x_train, x_test])\n",
    "all_digits = all_digits.astype(\"float32\") / 255.0\n",
    "all_digits = np.reshape(all_digits, (-1, 28, 28, 1))\n",
    "\n",
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_train = np.reshape(x_train, (-1, 28, 28, 1))\n",
    "\n",
    "x_test = x_test.astype(\"float32\") / 255.0\n",
    "x_test = np.reshape(x_test, (-1, 28, 28, 1))\n",
    "\n",
    "print(np.shape(all_digits))\n",
    "print(np.shape(x_train))\n",
    "print(np.shape(x_test))\n",
    "\n",
    "batch_size = config.batch_size\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(all_digits)\n",
    "dataset = dataset.shuffle(buffer_size = 1024).batch(batch_size)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(x_train)\n",
    "train_dataset = train_dataset.shuffle(buffer_size = 1024).batch(batch_size)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(x_test)\n",
    "test_dataset = test_dataset.shuffle(buffer_size = 1024).batch(batch_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range = 13,\n",
    "    zoom_range = 0.1, \n",
    "    shear_range = 10, \n",
    "    width_shift_range = 0.03,\n",
    "    height_shift_range = 0.03,\n",
    ")\n",
    "\n",
    "datagen.fit(x_train)\n",
    "\n",
    "train_generator = datagen.flow(x_train, batch_size = config.batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb0afb92c70>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = random.randint(0, 100)\n",
    "i = random.randint(0, 31)\n",
    "random_image = train_generator.__getitem__(idx)[i].reshape(28,28)\n",
    "\n",
    "\n",
    "plt.imshow(random_image, cmap = 'gray')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TCAE (MASKS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 128)       1280      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 28, 28, 128)      512       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " activation (Activation)     (None, 28, 28, 128)       0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 128)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 14, 14, 64)        73792     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 7, 7, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 7, 7, 64)          36928     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 7, 7, 64)          0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 4, 4, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 4, 4, 32)          18464     \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 4, 4, 32)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                8208      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 139,184\n",
      "Trainable params: 138,928\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1 (Dense)             (None, 1568)              26656     \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 7, 7, 32)          0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 7, 7, 32)         9248      \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 7, 7, 32)          0         \n",
      "                                                                 \n",
      " up_sampling2d (UpSampling2D  (None, 14, 14, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 14, 14, 32)       9248      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 14, 14, 32)        0         \n",
      "                                                                 \n",
      " up_sampling2d_1 (UpSampling  (None, 28, 28, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 28, 28, 64)       18496     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 28, 28, 64)        0         \n",
      "                                                                 \n",
      " conv2d_transpose_3 (Conv2DT  (None, 28, 28, 128)      73856     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 28, 28, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 28, 28, 128)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_4 (Conv2DT  (None, 28, 28, 1)        513       \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,529\n",
      "Trainable params: 138,273\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (28,28,1)\n",
    "\n",
    "latent_dim = config.latent_dim\n",
    "\n",
    "# encoder \n",
    "\n",
    "def make_encoder(num_layers, num_filters_1, num_filters_2, num_filters_3):\n",
    "\n",
    "    init_filters = num_filters_1\n",
    "\n",
    "    encoder = keras.Sequential()\n",
    "    encoder.add(keras.Input(shape = input_shape))\n",
    "    encoder.add(layers.Conv2D(init_filters, (3,3), padding = 'same'))\n",
    "    encoder.add(layers.BatchNormalization())\n",
    "    encoder.add(layers.Activation('relu'))\n",
    "    encoder.add(layers.MaxPooling2D((2,2),padding = 'same'))\n",
    "\n",
    "    for i in range(2):\n",
    "        encoder.add(layers.Conv2D(num_filters_2, (3,3), activation = 'relu', padding = 'same'))\n",
    "        encoder.add(layers.Activation('relu'))\n",
    "        encoder.add(layers.MaxPooling2D((2,2),padding = 'same'))\n",
    "\n",
    "    for i in range(num_layers-2):\n",
    "        encoder.add(layers.Conv2D(num_filters_3, (3,3), activation = 'relu', padding = 'same'))\n",
    "        encoder.add(layers.Activation('relu'))\n",
    "\n",
    "    encoder.add(layers.Flatten())\n",
    "    encoder.add(layers.Dense(latent_dim, activation = 'relu'))  \n",
    "\n",
    "    return encoder\n",
    "\n",
    "# decoder\n",
    "\n",
    "def make_decoder(num_layers, num_filters_1, num_filters_2, num_filters_3):\n",
    "\n",
    "    decoder = keras.Sequential()\n",
    "    decoder.add(keras.Input(shape = (latent_dim,)))\n",
    "    decoder.add(layers.Dense(7*7*32, activation = 'relu'))\n",
    "    decoder.add(layers.Reshape(target_shape = (7,7,32)))\n",
    "\n",
    "    for i in range(2):\n",
    "        decoder.add(Conv2DTranspose(num_filters_1, (3,3), padding = 'same'))\n",
    "        decoder.add(layers.Activation('relu'))\n",
    "        decoder.add(UpSampling2D((2,2)))\n",
    "    \n",
    "    for i in range(num_layers-2):\n",
    "        decoder.add(Conv2DTranspose(num_filters_2, (3,3), padding = 'same'))\n",
    "        decoder.add(layers.Activation('relu'))\n",
    "        \n",
    "    decoder.add(Conv2DTranspose(num_filters_3, (3,3), padding = 'same'))\n",
    "    decoder.add(layers.BatchNormalization())\n",
    "    decoder.add(layers.Activation('relu'))\n",
    "\n",
    "    decoder.add(Conv2DTranspose(1, (2,2), padding = 'same'))\n",
    "    decoder.add(layers.Activation('sigmoid'))\n",
    "\n",
    "    return decoder\n",
    "\n",
    "# define number of layers\n",
    "num_encoding_layers = config.num_encoding_layers\n",
    "num_decoding_layers = config.num_decoding_layers\n",
    "\n",
    "# make encoder\n",
    "encoder = make_encoder(num_layers = num_encoding_layers, \n",
    "                       num_filters_1 = config.enc_num_filters_1, \n",
    "                       num_filters_2 = config.enc_num_filters_2, \n",
    "                       num_filters_3 = config.enc_num_filters_3)\n",
    "encoder.summary()\n",
    "\n",
    "'''# get preflattened shape \n",
    "pre_flatten_shape = K.int_shape(encoder.layers[-3].output)[1:]\n",
    "print(pre_flatten_shape)\n",
    "\n",
    "dense_out = 1\n",
    "for elem in pre_flatten_shape:\n",
    "    dense_out *= elem'''\n",
    "\n",
    "# make decoder \n",
    "decoder = make_decoder(num_layers = num_decoding_layers, \n",
    "                       num_filters_1 = config.dec_num_filters_1, \n",
    "                       num_filters_2 = config.dec_num_filters_2, \n",
    "                       num_filters_3 = config.dec_num_filters_3)\n",
    "\n",
    "decoder.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TCAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.avg_loss_tracker = keras.metrics.Mean(name = 'avg_loss')\n",
    "        self.avg_accuracy_tracker = keras.metrics.Mean(name = 'avg_accuracy')\n",
    "\n",
    "    def compile(self, optimizer, loss_fn, accuracy_fn):\n",
    "        super().compile()\n",
    "        self.optimizer = optimizer \n",
    "        self.loss_fn = loss_fn\n",
    "        self.accuracy_fn = accuracy_fn\n",
    "\n",
    "    def train_step(self, data):\n",
    "\n",
    "        avg_loss = 0\n",
    "        avg_accuracy = 0\n",
    "\n",
    "        for i in range(int(np.log2(latent_dim)+1)):\n",
    "\n",
    "            with tf.GradientTape() as tape:\n",
    "                # create mask\n",
    "                ones_length = int(2**(np.log2(latent_dim)-i))\n",
    "                zeros_length = int(latent_dim - ones_length)\n",
    "                ones = tf.ones((ones_length)) \n",
    "                zeros = tf.zeros((zeros_length))\n",
    "                mask = tf.concat([ones, zeros], axis = 0) \n",
    "                mask = tf.reshape(mask, (1,latent_dim))\n",
    "     \n",
    "                codes = self.encoder(data)\n",
    "                masked_codes = tf.multiply(codes, mask)\n",
    "                #print(codes.shape)\n",
    "                #print(mask.shape)\n",
    "                #print(masked_codes.shape)\n",
    "                #masked_codes = tf.reshape(masked_codes, (tf.shape(codes)[0], latent_dim))\n",
    "                \n",
    "                reconstruction = self.decoder(masked_codes)\n",
    "\n",
    "                loss = self.loss_fn(data, reconstruction)\n",
    "                accuracy = self.accuracy_fn(data, reconstruction)\n",
    "            \n",
    "            avg_loss += loss\n",
    "            avg_accuracy += accuracy\n",
    "            # get gradients\n",
    "            grads = tape.gradient(loss, self.trainable_weights)\n",
    "            # apply gradients\n",
    "            self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "\n",
    "        avg_loss = avg_loss / int(np.log2(latent_dim)+1)\n",
    "        avg_accuracy = avg_accuracy / int(np.log2(latent_dim+1))\n",
    "            \n",
    "        self.avg_loss_tracker.update_state(avg_loss)\n",
    "        self.avg_accuracy_tracker.update_state(avg_accuracy)\n",
    "\n",
    "        return {\n",
    "            'avg_loss': self.avg_loss_tracker.result(),\n",
    "            'avg_accuracy': self.avg_accuracy_tracker.result()\n",
    "        }\n",
    "\n",
    "    def custom_predict(self, data, n):\n",
    "\n",
    "        # create mask\n",
    "        ones_length = int(2**(n))\n",
    "        zeros_length = int(latent_dim - ones_length)\n",
    "        ones = tf.ones((ones_length)) \n",
    "        zeros = tf.zeros((zeros_length))\n",
    "        mask = tf.concat([ones, zeros], axis = 0) \n",
    "        mask = tf.reshape(mask, (1,latent_dim))\n",
    "\n",
    "        codes = self.encoder(data)\n",
    "        masked_codes = tf.multiply(codes, mask)\n",
    "        #masked_codes = tf.reshape(masked_codes, (1, latent_dim))\n",
    "        \n",
    "        reconstruction = self.decoder(masked_codes)\n",
    "\n",
    "        return reconstruction\n",
    "\n",
    "    def test_step(self, data):\n",
    "        \n",
    "        avg_loss = 0\n",
    "        avg_accuracy = 0\n",
    "\n",
    "        for i in range(int(np.log2(latent_dim)+1)):\n",
    "            # create mask\n",
    "            ones_length = int(2**(np.log2(latent_dim)-i))\n",
    "            zeros_length = int(latent_dim - ones_length)\n",
    "            ones = tf.ones((ones_length)) \n",
    "            zeros = tf.zeros((zeros_length))\n",
    "            mask = tf.concat([ones, zeros], axis = 0) \n",
    "            mask = tf.reshape(mask, (1,latent_dim))\n",
    "\n",
    "            # mask codes\n",
    "            codes = self.encoder(data)\n",
    "            masked_codes = tf.multiply(codes, mask)        \n",
    "            reconstruction = self.decoder(masked_codes)\n",
    "\n",
    "            loss = self.loss_fn(data, reconstruction)\n",
    "            accuracy = self.accuracy_fn(data, reconstruction)\n",
    "            \n",
    "            avg_loss += loss\n",
    "            avg_accuracy += accuracy\n",
    "        \n",
    "        avg_loss = avg_loss / int(np.log2(latent_dim)+1)\n",
    "        avg_accuracy = avg_accuracy / int(np.log2(latent_dim+1))\n",
    "            \n",
    "        self.avg_loss_tracker.update_state(avg_loss)\n",
    "        self.avg_accuracy_tracker.update_state(avg_accuracy)\n",
    "\n",
    "\n",
    "        return {\n",
    "            'avg_loss': self.avg_loss_tracker.result(),\n",
    "            'avg_accuracy': self.avg_accuracy_tracker.result()\n",
    "        }\n",
    "    \n",
    "    def call(self, data):\n",
    "        codes = self.encoder(data)\n",
    "        reconstruction = self.decoder(codes)\n",
    "\n",
    "        return reconstruction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# test masking \n",
    "\n",
    "i = 2\n",
    "\n",
    "ones_length = int(2**(i))\n",
    "zeros_length = int(latent_dim - ones_length)\n",
    "ones = tf.ones((ones_length)) \n",
    "zeros = tf.zeros((zeros_length))\n",
    "mask = tf.concat([ones, zeros], axis = 0)\n",
    "mask = tf.reshape(mask, (1, latent_dim,))\n",
    "\n",
    "a = mask.numpy()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize tcae\n",
    "\n",
    "tcae = TCAE(encoder = encoder, decoder = decoder)\n",
    "tcae.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001), \n",
    "             loss_fn = tf.keras.losses.binary_crossentropy, \n",
    "             accuracy_fn = tf.keras.metrics.BinaryAccuracy(name=\"binary_accuracy\", dtype=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using `save_best_only`, ensure that the `filepath` argument contains formatting placeholders like `{epoch:02d}` or `{batch:02d}`. This ensures correct interpretation of the logged artifacts.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "938/938 [==============================] - ETA: 0s - avg_loss: 0.2144 - avg_accuracy: 0.9201"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./models)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 1982s 2s/step - avg_loss: 0.2144 - avg_accuracy: 0.9201 - val_avg_loss: 0.1792 - val_avg_accuracy: 1.0096\n",
      "Epoch 2/3\n",
      "938/938 [==============================] - ETA: 0s - avg_loss: 0.1945 - avg_accuracy: 0.9218"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./models)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 1704s 2s/step - avg_loss: 0.1945 - avg_accuracy: 0.9218 - val_avg_loss: 0.1704 - val_avg_accuracy: 1.0120\n",
      "Epoch 3/3\n",
      "938/938 [==============================] - ETA: 0s - avg_loss: 0.1897 - avg_accuracy: 0.9220"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./models)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 1740s 2s/step - avg_loss: 0.1897 - avg_accuracy: 0.9220 - val_avg_loss: 0.1651 - val_avg_accuracy: 1.0139\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch/avg_accuracy</td><td>▁▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▆▆▆█▇▇▆▆▆▆▆▆▆▆▆▆</td></tr><tr><td>batch/avg_loss</td><td>█▆▅▄▄▄▃▃▃▃▃▃▃▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>batch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/avg_accuracy</td><td>▁██</td></tr><tr><td>epoch/avg_loss</td><td>█▂▁</td></tr><tr><td>epoch/epoch</td><td>▁▅█</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁</td></tr><tr><td>epoch/val_avg_accuracy</td><td>▁▅█</td></tr><tr><td>epoch/val_avg_loss</td><td>█▄▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch/avg_accuracy</td><td>0.92196</td></tr><tr><td>batch/avg_loss</td><td>0.18972</td></tr><tr><td>batch/batch_step</td><td>2815</td></tr><tr><td>batch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/avg_accuracy</td><td>0.92196</td></tr><tr><td>epoch/avg_loss</td><td>0.18972</td></tr><tr><td>epoch/epoch</td><td>2</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/val_avg_accuracy</td><td>1.01394</td></tr><tr><td>epoch/val_avg_loss</td><td>0.16508</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">stoic-violet-24</strong> at: <a href='https://wandb.ai/cuzime/prelim%20/runs/01gyrtm7' target=\"_blank\">https://wandb.ai/cuzime/prelim%20/runs/01gyrtm7</a><br/>Synced 6 W&B file(s), 0 media file(s), 15 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230309_214150-01gyrtm7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = config.epochs\n",
    "\n",
    "tcae.fit(train_generator, epochs = epochs, validation_data = test_dataset,\n",
    "                   callbacks = [\n",
    "                    WandbMetricsLogger(log_freq=5),\n",
    "                    WandbModelCheckpoint(\"models\", save_best_only = True, monitor = 'val_avg_loss')\n",
    "                   ])\n",
    "wandb.finish()\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"save weights\"\"\"\n",
    "#tcae.save_weights('/Users/andrewgoh/Desktop/NDC/weights/tcae_weights', overwrite=True, save_format=None, options=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"load weights\"\"\"\n",
    "\"\"\"tcae = TCAE(encoder = encoder, decoder = decoder)\n",
    "tcae.load_weights('/Users/andrewgoh/Desktop/NDC/weights/tcae_weights', by_name=False, skip_mismatch=False, options=None)\n",
    "\n",
    "# set optimizer and compile \n",
    "tcae.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001), loss_fn = tf.keras.losses.BinaryCrossentropy())\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x360 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = random.randint(0, np.shape(all_digits)[0]-1)\n",
    "img = all_digits[index,:,:,0]\n",
    "\n",
    "plt.figure(figsize = (3,3))\n",
    "plt.imshow(img)\n",
    "\n",
    "img = img.reshape(1, 28, 28, 1)\n",
    "\n",
    "plt.figure(figsize = (16,5))\n",
    "for i in range(int(np.log2(latent_dim))+1):\n",
    "    ax = plt.subplot(2, 8, i + 1)\n",
    "    reconstruction = tcae.custom_predict([img], np.log2(latent_dim)-i)\n",
    "    reconstruction = reconstruction.numpy().reshape(28,28)\n",
    "    plt.title('latent dim:{}'.format(int(2**(np.log2(latent_dim)-i))))\n",
    "    plt.imshow(reconstruction)\n",
    "    plt.axis('off')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
